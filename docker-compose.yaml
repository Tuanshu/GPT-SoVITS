# version: '3.8'
services:
  gpt-sovits-v3:
    #image: breakstring/gpt-sovits:latest   # please change the image name and tag base your environment. If the tag contains the word 'elite', such as "latest-elite", it indicates that the image does not include the necessary models such as GPT-SoVITS, UVR5, Damo ASR, etc. You will need to download them yourself and map them into the container.
    # image: msoo.ces.myfiinet.com:6702/gpt-sovits:0.1.0-20241203
    image: msoo.ces.myfiinet.com:6702/gpt-sovits:0.2.0-20241204-v2
    build:
      context: .
      dockerfile: Dockerfile_v1tov2
    container_name: gpt-sovits-container-v3
    environment:
      - is_half=False
      - is_share=False
    volumes:
      - ./output:/workspace/output
      - ./logs:/workspace/logs
      - ./SoVITS_weights:/workspace/SoVITS_weights
      - ./reference:/workspace/reference
      - .:/workspace
    working_dir: /workspace
    ports:
      - "6616:9880" # api
      # - "9871:9871"
      - "6617:9872" # infer webui
      - "6618:9873" # infer webui
      # - "9873:9873"
      # - "9874:9874"
    shm_size: 16G
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #count: "all"
              capabilities: [gpu]
              device_ids: ["1"]
    #command: ["sh", "-c", "python api_v3.py"]
    # command: ["sh", "-c", "python api_v2.py", "&&", "python GPT_SoVITS/inference_webui.py"]
    #command: ["sh", "-c", "python GPT_SoVITS/inference_webui_fast.py"]
    # command: ["sh", "-c", "python GPT_SoVITS/inference_hugginface_clean.py"]
    command: ["sh", "-c", "python api_v2.py & python GPT_SoVITS/inference_hugginface_clean.py & python GPT_SoVITS/inference_webui.py"]

    stdin_open: true
    tty: true
    restart: unless-stopped
